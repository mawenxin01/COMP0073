#!/usr/bin/env python3
"""
Medical Triage Frontend Application - Flask Backend
Provides real-time triage prediction API using RAG + GPT models
"""

from flask import Flask, render_template, request, jsonify
from flask_cors import CORS
import pandas as pd
import numpy as np
import json
import time
import sys
import os

# Ê∑ªÂä†È°πÁõÆÊ†πÁõÆÂΩïÂà∞Ë∑ØÂæÑ
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# ÂØºÂÖ•RAGÁ≥ªÁªü
try:
    from methods.llama_rag.llama_rag_triage import LlamaRAGTriageSystem
    LlamaRAGTriage = LlamaRAGTriageSystem
except ImportError as e:
    print(f"‚ö†Ô∏è Unable to import Llama RAG system: {e}")
    print("‚ö†Ô∏è Will use simulation mode")
    LlamaRAGTriage = None

# ÂØºÂÖ•‰º†ÁªüMLÁ≥ªÁªüÈúÄË¶ÅÁöÑÂ∫ì
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD

# ÂØºÂÖ•ÂøÖË¶ÅÁöÑÂ∫ì
import joblib
import numpy as np
import sys
import os

# Ê∑ªÂä†methodsÁõÆÂΩïÂà∞Ë∑ØÂæÑÔºå‰ª•‰æøÂØºÂÖ•CustomXGBClassifier
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'methods', 'tfidf_ml'))

# ÂØºÂÖ•CustomXGBClassifier
try:
    from methods.tfidf_ml.nosvd import CustomXGBClassifier
    print("‚úÖ CustomXGBClassifier imported successfully")
except ImportError as e:
    print(f"‚ö†Ô∏è Unable to import CustomXGBClassifier: {e}")
    CustomXGBClassifier = None

# ÂØºÂÖ•SHAPËß£ÈáäÊúçÂä°
try:
    from methods.llama_rag.shap_explainer_service import get_shap_explanation_for_prediction, initialize_shap_service
    print("‚úÖ SHAP explanation service imported successfully")
except ImportError as e:
    print(f"‚ö†Ô∏è Unable to import SHAP explanation service: {e}")
    get_shap_explanation_for_prediction = None
    initialize_shap_service = None

app = Flask(__name__)
CORS(app)  # ÂÖÅËÆ∏Ë∑®ÂüüËØ∑Ê±Ç

# ËæÖÂä©ÂáΩÊï∞
def _format_time_display(arrival_time):
    """Â∞ÜÂÆåÊï¥Êó∂Èó¥Ê†ºÂºèËΩ¨Êç¢‰∏∫Âè™ÊòæÁ§∫Êó∂ÂàÜÁöÑÊ†ºÂºè"""
    if not arrival_time:
        return None
    try:
        dt = pd.to_datetime(arrival_time)
        return dt.strftime('%H:%M')
    except:
        return arrival_time

# ÂÖ®Â±ÄÂèòÈáè
llama_rag_system = None
xgboost_model = None
tfidf_vectorizer = None  
svd_model = None  # SVDÈôçÁª¥Ê®°Âûã
feature_scaler = None
case_database = None
watsonx_client = None  # WatsonxÂÆ¢Êà∑Á´Ø

class MockRAGSystem:
    """Mock RAG system for demonstration"""
    
    def __init__(self):
        self.embedding_model = None
        self.faiss_index = None
        
    def predict_triage_level(self, patient_info, k=5):
        """Mock triage prediction"""
        
        # ÁÆÄÂçïÁöÑËßÑÂàôÂºïÊìé
        chief_complaint = patient_info.get('chief_complaint', '').lower()
        heart_rate = patient_info.get('heart_rate', 80)
        sbp = patient_info.get('sbp', 120)
        dbp = patient_info.get('dbp', 80)
        temperature = patient_info.get('temperature', 98.6)
        o2sat = patient_info.get('o2sat', 98)
        pain = patient_info.get('pain', 5)
        age = patient_info.get('age', 50)
        
        # Âç±ÈáçÁóáÁä∂ÂÖ≥ÈîÆËØç
        critical_keywords = ['chest pain', 'shortness of breath', 'unconscious', 'cardiac arrest', 
                           'stroke', 'seizure', 'trauma', 'bleeding', 'shock']
        
        # ‰∏•ÈáçÁóáÁä∂ÂÖ≥ÈîÆËØç
        severe_keywords = ['fever', 'vomiting', 'diarrhea', 'headache', 'abdominal pain', 
                          'dizziness', 'weakness', 'nausea']
        
        # ÁîüÂëΩ‰ΩìÂæÅËØÑ‰º∞
        vital_score = 0
        if heart_rate > 100 or heart_rate < 60:
            vital_score += 1
        if sbp < 90 or sbp > 180:
            vital_score += 1
        if temperature > 100.4:
            vital_score += 1
        if o2sat < 95:
            vital_score += 1
        if pain > 7:
            vital_score += 1
        
        # Âπ¥ÈæÑÈ£éÈô©
        age_risk = 0
        if age > 65:
            age_risk = 1
        
        # ÂàÜËØäÁ≠âÁ∫ßÂà§Êñ≠
        if any(keyword in chief_complaint for keyword in critical_keywords) or vital_score >= 3:
            triage_level = 1  # Âç±Èáç
            confidence = 0.85
            reasoning = "ÊÇ£ËÄÖË°®Áé∞Âá∫Âç±ÈáçÁóáÁä∂ÊàñÁîüÂëΩ‰ΩìÂæÅÂºÇÂ∏∏ÔºåÈúÄË¶ÅÁ´ãÂç≥ÂåªÁñóÂπ≤È¢Ñ"
        elif any(keyword in chief_complaint for keyword in severe_keywords) or vital_score >= 2 or age_risk:
            triage_level = 2  # ‰∏•Èáç
            confidence = 0.75
            reasoning = "ÊÇ£ËÄÖÁóáÁä∂‰∏•ÈáçÊàñÂ≠òÂú®È£éÈô©Âõ†Á¥†ÔºåÈúÄË¶ÅÂèäÊó∂ÂåªÁñóËØÑ‰º∞"
        elif vital_score >= 1 or pain > 5:
            triage_level = 3  # ‰∏≠Á≠â
            confidence = 0.70
            reasoning = "ÊÇ£ËÄÖÁóáÁä∂‰∏≠Á≠âÔºåÈúÄË¶ÅÂåªÁñóËØÑ‰º∞‰ΩÜÈùûÁ¥ßÊÄ•"
        else:
            triage_level = 4  # ËΩªÂæÆ
            confidence = 0.80
            reasoning = "ÊÇ£ËÄÖÁóáÁä∂ËΩªÂæÆÔºåÂèØ‰ª•Á≠âÂæÖÂ∏∏ËßÑÂåªÁñóËØÑ‰º∞"
        
        # ËøîÂõû‰∏éÁúüÂÆûLlamaRAGTriageSystemÁõ∏ÂêåÁöÑÊ†ºÂºèÔºö(triage_level, reasoning, similar_cases, similarities)
        similar_cases = [
            {'chief_complaint': 'chest pain', 'triage_level': 1, 'outcome': 'MI confirmed'},
            {'chief_complaint': 'fever and cough', 'triage_level': 2, 'outcome': 'Pneumonia'},
            {'chief_complaint': 'headache', 'triage_level': 3, 'outcome': 'Tension headache'}
        ]
        similarities = [0.85, 0.75, 0.65]  # Ê®°ÊãüÁõ∏‰ººÂ∫¶ÂàÜÊï∞
        
        return triage_level, reasoning, similar_cases, similarities

def initialize_systems():
    """ÂàùÂßãÂåñÊâÄÊúâÈ¢ÑÊµãÁ≥ªÁªü"""
    global llama_rag_system, xgboost_model, feature_scaler, case_database
    
    # 1. ÂàùÂßãÂåñLlama RAGÁ≥ªÁªü - Áõ¥Êé•Âä†ËΩΩÈ¢ÑÊûÑÂª∫ÁöÑÁ¥¢Âºï
    try:
        if LlamaRAGTriage:
            print("üöÄ Initializing Llama RAG system...")
            llama_rag_system = LlamaRAGTriage()
            
            # Áõ¥Êé•Âä†ËΩΩÈ¢ÑÊûÑÂª∫ÁöÑÁ¥¢ÂºïÔºå‰∏çÊ∂âÂèäÂéüÂßãÊï∞ÊçÆ
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.join(current_dir, "..")
            
            # Â∞ùËØïÂä†ËΩΩÂ∑≤ËÆ≠ÁªÉÂ•ΩÁöÑÁ¥¢ÂºïÔºàÊåâ‰ºòÂÖàÁ∫ßÔºâ
            possible_index_paths = [
                os.path.join(project_root, "methods/llama_rag/llama_rag_train_only_index_stable"),  # Á®≥ÂÆöÁâàÊú¨Á¥¢Âºï
                # Â¶ÇÊûúÁ¥¢Âºï‰∏çÂ≠òÂú®ÔºåÂàôÊèêÁ§∫Áî®Êà∑ÂÖàËøêË°åËÆ≠ÁªÉ
            ]
            
            loaded = False
            for index_path in possible_index_paths:
                print(f"üîç Attempting to load index: {index_path}")
                # Check if FAISS index files exist (need both .index and .pkl files)
                faiss_index_path = f"{index_path}_faiss.index"
                metadata_path = f"{index_path}_metadata.pkl"
                
                if os.path.exists(faiss_index_path) and os.path.exists(metadata_path):
                    print(f"‚úÖ Found pre-built index: {index_path}")
                    try:
                        # ÂàùÂßãÂåñÁúüÂÆûÁöÑLlama RAGÁ≥ªÁªü
                        from methods.llama_rag.llama_rag_triage import LlamaRAGTriageSystem
                        llama_rag_system = LlamaRAGTriageSystem()
                        # Âä†ËΩΩÈ¢ÑÊûÑÂª∫Á¥¢Âºï
                        llama_rag_system.case_retriever.vector_store.load_index(index_path)
                        
                        # Ê†áËÆ∞Á≥ªÁªü‰∏∫Â∑≤ÂàùÂßãÂåñ
                        llama_rag_system.case_retriever.initialized = True
                        llama_rag_system.is_initialized = True
                        
                        print(f"‚úÖ Successfully loaded pre-built index: {index_path}")
                        loaded = True
                        
                        # Ê£ÄÊü•Á¥¢ÂºïÊï∞ÊçÆÈáèÔºåË≠¶ÂëäÊΩúÂú®ÁöÑÊï∞ÊçÆÊ≥ÑÊºè
                        if hasattr(llama_rag_system.case_retriever, 'vector_store') and hasattr(llama_rag_system.case_retriever.vector_store, 'case_database'):
                            indexed_count = len(llama_rag_system.case_retriever.vector_store.case_database)
                            expected_train_size = int(189780 * 0.8)  # Á∫¶151,824
                            print(f"üìä Loaded index contains {indexed_count} cases")
                            
                            if indexed_count > (expected_train_size + 5000):
                                print(f"‚ö†Ô∏è Data leakage warning: Index data size ({indexed_count}) exceeds expected training size ({expected_train_size})")
                                print(f"   May contain test data, evaluation results may be inflated")
                            elif indexed_count < (expected_train_size - 5000):
                                print(f"‚ö†Ô∏è Data size too small: Index data size ({indexed_count}) less than expected training size")
                            else:
                                print(f"‚úÖ Index data size reasonable: {indexed_count} cases (expected ~{expected_train_size})")
                        break
                        
                    except Exception as e:
                        print(f"‚ùå Failed to load index: {e}")
                        continue
                else:
                    print(f"‚ö†Ô∏è Index does not exist or failed to load: {index_path}")
            
            if not loaded:
                print("‚ùå No available pre-built index found")
                print("üí° Please run the following commands to build index:")
                print("   cd medical_triage_assistant/methods/llama_rag")
                print("   python llama_rag_triage.py")
                print("‚ö†Ô∏è Temporarily using simulation mode")
                llama_rag_system = MockRAGSystem()
            else:
                print("‚úÖ Llama RAG system initialization complete (using pre-built index)")
                
        else:
            print("‚ö†Ô∏è ‰ΩøÁî®Ê®°ÊãüLlama RAGÁ≥ªÁªü")
            llama_rag_system = MockRAGSystem()
            
    except Exception as e:
        print(f"‚ùå Llama RAGÁ≥ªÁªüÂàùÂßãÂåñÂ§±Ë¥•: {e}")
        print("‚ö†Ô∏è ‰ΩøÁî®Ê®°ÊãüÊ®°Âºè")
        llama_rag_system = MockRAGSystem()
    
    # 2. ÂàùÂßãÂåñTFIDF + Random ForestÊ®°Âûã
    global xgboost_model, tfidf_vectorizer, svd_model, watsonx_client
    try:
        print("üéØ ÂàùÂßãÂåñTFIDF + Random ForestÊ®°Âûã...")
        
        # Á°Æ‰øùproject_rootÂ∑≤ÂÆö‰πâ
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.join(current_dir, "..")
        
        # Âä†ËΩΩTFIDF + Random ForestÊ®°Âûã
        xgboost_path = os.path.join(project_root, "models", "TFIDF-rf.pkl")
        vectorizer_path = os.path.join(project_root, "models", "TFIDF-rf-vectorizer.pkl")
        svd_path = os.path.join(project_root, "models", "TFIDF-rf-svd.pkl")
        
        if os.path.exists(xgboost_path):
            xgboost_model = joblib.load(xgboost_path)
            print("‚úÖ TFIDF + Random ForestÊ®°ÂûãÂä†ËΩΩÊàêÂäü")
            
            # Âä†ËΩΩTF-IDFÂêëÈáèÂåñÂô®
            if os.path.exists(vectorizer_path):
                tfidf_vectorizer = joblib.load(vectorizer_path)
                print("‚úÖ TF-IDFÂêëÈáèÂåñÂô®Âä†ËΩΩÊàêÂäü")
            else:
                print(f"‚ùå TF-IDFÂêëÈáèÂåñÂô®Êñá‰ª∂‰∏çÂ≠òÂú®: {vectorizer_path}")
                tfidf_vectorizer = None
            
            # Âä†ËΩΩSVDÊ®°Âûã
            if os.path.exists(svd_path):
                svd_model = joblib.load(svd_path)
                print("‚úÖ SVDÊ®°ÂûãÂä†ËΩΩÊàêÂäü")
            else:
                print(f"‚ùå SVDÊ®°ÂûãÊñá‰ª∂‰∏çÂ≠òÂú®: {svd_path}")
                svd_model = None
                
        else:
            print(f"‚ùå TFIDF + Random ForestÊ®°ÂûãÊñá‰ª∂‰∏çÂ≠òÂú®: {xgboost_path}")
            xgboost_model = None
            tfidf_vectorizer = None
            svd_model = None
        
        # ÂàùÂßãÂåñWatsonxÂÆ¢Êà∑Á´Ø
        try:
            from medical_triage_assistant.config.azure_simple import IBM_API_KEY, IBM_ENDPOINT, IBM_PROJECT_ID, IBM_MODEL_NAME
            from ibm_watsonx_ai.foundation_models import ModelInference
            from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as Meta
            from ibm_watsonx_ai import Credentials
            
            credentials = Credentials(api_key=IBM_API_KEY, url=IBM_ENDPOINT)
            watsonx_client = ModelInference(
                model_id=IBM_MODEL_NAME,
                credentials=credentials,
                project_id=IBM_PROJECT_ID,
                params={Meta.MAX_NEW_TOKENS: 100, Meta.TEMPERATURE: 0.1}
            )
            print("‚úÖ WatsonxÂÆ¢Êà∑Á´ØÂàùÂßãÂåñÊàêÂäü")
        except Exception as e:
            print(f"‚ö†Ô∏è WatsonxÂÆ¢Êà∑Á´ØÂàùÂßãÂåñÂ§±Ë¥•: {e}")
            watsonx_client = None
            
    except Exception as e:
        print(f"‚ùå TFIDF + Random ForestÊ®°ÂûãÂàùÂßãÂåñÂ§±Ë¥•: {e}")
        print(f"ÈîôËØØËØ¶ÊÉÖ: {str(e)}")
        xgboost_model = None
        watsonx_client = None
    
    # 3. ÂàùÂßãÂåñSHAPËß£ÈáäÊúçÂä°
    try:
        print("üîç ÂàùÂßãÂåñSHAPËß£ÈáäÊúçÂä°...")
        if initialize_shap_service:
            if initialize_shap_service():
                print("‚úÖ SHAPËß£ÈáäÊúçÂä°ÂàùÂßãÂåñÊàêÂäü")
            else:
                print("‚ö†Ô∏è SHAPËß£ÈáäÊúçÂä°ÂàùÂßãÂåñÂ§±Ë¥•")
        else:
            print("‚ö†Ô∏è SHAPËß£ÈáäÊúçÂä°‰∏çÂèØÁî®")
    except Exception as e:
        print(f"‚ùå SHAPËß£ÈáäÊúçÂä°ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
        


@app.route('/')
def index():
    """‰∏ªÈ°µ"""
    return render_template('index.html')

@app.route('/api/predict', methods=['POST'])
def predict_triage():
    """ÂàÜËØäÈ¢ÑÊµãAPI"""
    
    try:
        # Á°Æ‰øùÁ≥ªÁªüÂ∑≤ÂàùÂßãÂåñ
        global llama_rag_system, xgboost_model, watsonx_client
        if llama_rag_system is None or xgboost_model is None:
            initialize_systems()
            
        # Ëé∑ÂèñÊÇ£ËÄÖ‰ø°ÊÅØ
        data = request.get_json()
        
        # È™åËØÅÂøÖÈúÄÂ≠óÊÆµ
        required_fields = ['chief_complaint', 'age', 'heart_rate', 'sbp', 'dbp', 'temperature', 'o2sat', 'pain']
        for field in required_fields:
            if field not in data:
                return jsonify({'error': f'Missing required field: {field}'}), 400
        
        # ËÆ∞ÂΩïËØ∑Ê±ÇÊó∂Èó¥
        start_time = time.time()
        
        # Ëé∑ÂèñÈÄâÊã©ÁöÑÊ®°Âûã
        selected_model = data.get('model', 'gpt_rag')
        
        # ÊûÑÂª∫ÊÇ£ËÄÖ‰ø°ÊÅØ
        patient_info = {
            'chiefcomplaint': data['chief_complaint'],
            'chief_complaint': data['chief_complaint'],  # ‰∏∫‰º†ÁªüML‰øùÁïô
            'age_at_visit': data['age'],
            'age': data['age'],  # ‰∏∫‰º†ÁªüML‰øùÁïô
            'heartrate': data['heart_rate'],
            'heart_rate': data['heart_rate'],  # ‰∏∫‰º†ÁªüML‰øùÁïô
            'sbp': data['sbp'],
            'dbp': data['dbp'],
            'temperature': data['temperature'],
            'o2sat': data['o2sat'],
            'pain': data['pain'],
            'gender': data.get('gender', 'Unknown'),
            'arrival_transport': data.get('arrival_transport', 'WALK IN'),
            'arrival_time': pd.to_datetime(data.get('arrival_time', None)).strftime('%H:%M') if data.get('arrival_time', None) else None  # Âè™ÊòæÁ§∫Êó∂ÂàÜ
        }
        
        # Ê†πÊçÆÈÄâÊã©ÁöÑÊ®°ÂûãËøõË°åÈ¢ÑÊµã
        print(f"üîç Selected model: {selected_model}")
        
        if selected_model == 'tfidf_rf':
            # ‰ΩøÁî®TFIDF + Random ForestÊ®°ÂûãËøõË°åÈ¢ÑÊµã
            print("üìä Using TFIDF + Random Forest model for prediction")
            
            try:
                if xgboost_model is not None:
                    if tfidf_vectorizer is not None and svd_model is not None:
                        print("‚úÖ Using TFIDF + Random Forest model (complete 33 features)")
                    
                    # 1. ÊèêÂèñÂÖ≥ÈîÆËØç
                    chief_complaint = patient_info.get('chief_complaint', '')
                    keywords = chief_complaint  # ÈªòËÆ§‰ΩøÁî®ÂéüÂßãÊñáÊú¨
                    
                    if watsonx_client is not None:
                        try:
                            prompt = f"""
                            ‰Ωú‰∏∫ÂåªÁñó‰∏ìÂÆ∂ÔºåËØ∑‰ªé‰ª•‰∏ã‰∏ªËØâ‰∏≠ÊèêÂèñÊúÄÈáçË¶ÅÁöÑÂåªÂ≠¶ÂÖ≥ÈîÆËØçÔºåÁî®ÈÄóÂè∑ÂàÜÈöîÔºö

                            ‰∏ªËØâ: {chief_complaint}

                            ÂÖ≥ÈîÆËØç:"""
                            
                            response = watsonx_client.generate_text(prompt=prompt)
                            keywords = response.strip()
                            print(f"üîç Keywords extracted by Watsonx: {keywords}")
                        except Exception as e:
                            print(f"‚ö†Ô∏è Watsonx keyword extraction failed: {e}")
                    
                    # 2. Â§ÑÁêÜÊñáÊú¨ÁâπÂæÅÔºà‰ΩøÁî®ÁúüÊ≠£ÁöÑTF-IDF + SVDÔºâ
                    print(f"üîç Processing keywords: {keywords}")
                    
                    # TF-IDFÂèòÊç¢
                    keywords_tfidf = tfidf_vectorizer.transform([keywords])
                    print(f"‚úÖ TF-IDF feature shape: {keywords_tfidf.shape}")
                    
                    # SVDÈôçÁª¥
                    keywords_svd = svd_model.transform(keywords_tfidf)
                    print(f"‚úÖ SVD feature shape: {keywords_svd.shape}")
                    
                    # 3. Â§ÑÁêÜÊó∂Èó¥ÁâπÂæÅ
                    arrival_time = patient_info.get('arrival_time', '2024-01-15 12:00:00')
                    try:
                        dt = pd.to_datetime(arrival_time)
                        hour = dt.hour
                        if 0 <= hour < 6:
                            time_period = 0  # ÂáåÊô®
                        elif 6 <= hour < 12:
                            time_period = 1  # ‰∏äÂçà
                        elif 12 <= hour < 18:
                            time_period = 2  # ‰∏ãÂçà
                        else:
                            time_period = 3  # Êôö‰∏ä
                    except:
                        time_period = 2  # ÈªòËÆ§‰∏ãÂçà
                    
                    # 4. ÊûÑÂª∫Êï∞ÂÄºÁâπÂæÅÔºà8‰∏™Âü∫Á°ÄÊï∞ÂÄºÁâπÂæÅÔºâ
                    numerical_features = [
                        float(patient_info.get('age', 50)),
                        float(patient_info.get('pain', 0)),
                        float(patient_info.get('temperature', 98.6)),
                        float(patient_info.get('heart_rate', 80)),
                        float(patient_info.get('sbp', 120)),
                        float(patient_info.get('dbp', 80)),
                        float(patient_info.get('o2sat', 98)),
                        float(time_period)
                    ]
                    
                    # 5. Â§ÑÁêÜÂàÜÁ±ªÁâπÂæÅÔºà5‰∏™one-hotÁºñÁ†ÅÁâπÂæÅÔºâ
                    gender = patient_info.get('gender', 'Unknown').upper()
                    gender_m = 1 if gender == 'M' else 0
                    
                    transport = patient_info.get('arrival_transport', 'WALK IN').upper()
                    transport_helicopter = 1 if transport == 'HELICOPTER' else 0
                    transport_other = 1 if transport == 'OTHER' else 0
                    transport_unknown = 1 if transport == 'UNKNOWN' else 0
                    transport_walk_in = 1 if transport == 'WALK IN' else 0
                    
                    categorical_features = [
                        gender_m,
                        transport_helicopter,
                        transport_other,
                        transport_unknown,
                        transport_walk_in
                    ]
                    
                    # 6. ÂêàÂπ∂ÊâÄÊúâÁâπÂæÅÔºà33‰∏™ÁâπÂæÅÔºö8Êï∞ÂÄº + 5ÂàÜÁ±ª + 20 SVDÔºâ
                    all_features = np.concatenate([
                        numerical_features,        # 8‰∏™Êï∞ÂÄºÁâπÂæÅ
                        categorical_features,      # 5‰∏™ÂàÜÁ±ªÁâπÂæÅ  
                        keywords_svd.flatten()     # 20‰∏™SVDÁâπÂæÅ
                    ])
                    
                    print(f"‚úÖ Final feature vector shape: {all_features.shape} (should be 33)")
                    print(f"   Numerical features: {len(numerical_features)}")
                    print(f"   Categorical features: {len(categorical_features)}")
                    print(f"   SVD features: {keywords_svd.shape[1]}")
                    
                    # 7. ‰ΩøÁî®TFIDF + Random ForestÊ®°ÂûãÈ¢ÑÊµã
                    prediction = xgboost_model.predict([all_features])[0]
                    prediction_proba = xgboost_model.predict_proba([all_features])[0]
                    
                    # ËΩ¨Êç¢ÂõûÂéüÂßãÂàÜËØäÁ≠âÁ∫ß (0-4 -> 1-5)
                    triage_level = int(prediction) + 1
                    confidence = float(np.max(prediction_proba))
                    
                    # ÂàÜËØäÁ≠âÁ∫ßÂê´‰πâ
                    level_meanings = {
                        1: "Critical (Á´ãÂç≥)",
                        2: "Severe (ÊÄ•ËØä)",
                        3: "Moderate (Á¥ßÊÄ•)",
                        4: "Mild (ËæÉÊÄ•)",
                        5: "Minor (ÈùûÊÄ•)"
                    }
                    
                    # Ëé∑ÂèñSHAPËß£Èáä
                    shap_explanation = None
                    if get_shap_explanation_for_prediction:
                        try:
                            shap_explanation = get_shap_explanation_for_prediction(patient_info)
                            print("‚úÖ SHAPËß£ÈáäÁîüÊàêÊàêÂäü")
                        except Exception as e:
                            print(f"‚ö†Ô∏è SHAPËß£ÈáäÁîüÊàêÂ§±Ë¥•: {e}")
                    
                    # TFIDFÊ®°Âûã‰∏çÊèê‰æõreasoningÔºåÂè™ËøîÂõûÂàÜËØäÁ∫ßÂà´
                    reasoning = ""
                    
                    # ‰∏çÊèê‰æõÁõ∏‰ººÊ°à‰æã
                    similar_cases = []
                        
                else:
                    print("‚ö†Ô∏è TFIDF + Random ForestÊ®°Âûã‰∏çÂèØÁî®Ôºå‰ΩøÁî®Ê®°ÊãüÊ®°Âºè")
                    triage_level = 3
                    confidence = 0.5
                    reasoning = ""
                    similar_cases = []
                
            except Exception as e:
                print(f"‚ùå TFIDF + Random ForestÈ¢ÑÊµãÂ§±Ë¥•: {e}")
                triage_level = 3
                confidence = 0.0
                reasoning = ""
                similar_cases = []
                
            model_used = 'tfidf_rf'
            
        else:
            # ‰ΩøÁî®Llama RAGÁ≥ªÁªüÔºàÈªòËÆ§Ôºâ
            print(f"ü§ñ ‰ΩøÁî®Llama RAGÁ≥ªÁªüËøõË°åÈ¢ÑÊµã")
            if llama_rag_system is not None and hasattr(llama_rag_system, 'predict_triage_level'):
                # ÁúüÂÆûLlama RAGÁ≥ªÁªü
                print("‚úÖ ‰ΩøÁî®ÁúüÂÆûLlama RAGÁ≥ªÁªüÔºàVector-OnlyÊ£ÄÁ¥¢ - ÊúÄÂø´Ê®°ÂºèÔºâ")
                try:
                    # ËΩ¨Êç¢‰∏∫Â≠óÂÖ∏Ê†ºÂºè
                    case_dict = {
                        'chief_complaint': patient_info.get('chief_complaint', ''),
                        'age_at_visit': patient_info.get('age', 50),
                        'gender': patient_info.get('gender', 'Unknown'),
                        'heartrate': patient_info.get('heart_rate', 80),
                        'sbp': patient_info.get('sbp', 120),
                        'dbp': patient_info.get('dbp', 80),
                        'temperature': patient_info.get('temperature', 98.6),
                        'o2sat': patient_info.get('o2sat', 98),
                        'pain': patient_info.get('pain', 5),
                        'arrival_transport': patient_info.get('arrival_method', 'Unknown'),
                        'time_period': patient_info.get('time_period', 2)
                    }
                    
                    # Ë∞ÉÁî®LLaMA RAGÁ≥ªÁªüÔºà‰ΩøÁî®Vector-OnlyÊ£ÄÁ¥¢ - ÊúÄÂø´Ê®°ÂºèÔºâ
                    # ÊÄßËÉΩÈÖçÁΩÆÔºöVector-OnlyÊ®°ÂºèÔºåÊúÄÂø´ÁöÑÊ£ÄÁ¥¢ÈÄüÂ∫¶
                    k_retrieve = 5  # Vector-OnlyÊ£ÄÁ¥¢ (~30-50msÔºåÊúÄÂø´)
                    
                    start_retrieval = time.time()
                    triage_level, reasoning, similar_cases_raw, similarities = llama_rag_system.predict_triage_level(case_dict, k=k_retrieve)
                    retrieval_time = time.time() - start_retrieval
                    print(f"‚è±Ô∏è RAGÊ£ÄÁ¥¢+ÁîüÊàêÊó∂Èó¥: {retrieval_time:.3f}s")
                    
                    confidence = 0.8  # ÈªòËÆ§ÁΩÆ‰ø°Â∫¶
                    if similarities:
                        confidence = min(0.95, max(0.6, np.mean(similarities)))
                    
                    # ËΩ¨Êç¢Áõ∏‰ººÊ°à‰æãÊ†ºÂºè
                    similar_cases = []
                    if similar_cases_raw:
                        for i, case in enumerate(similar_cases_raw[:3]):  # ÂèñÂâç3‰∏™
                            # ÊûÑÂª∫ÂÆåÊï¥ÁöÑÊ°à‰æã‰ø°ÊÅØ
                            age = case.get('age_at_visit', case.get('age', 'N/A'))
                            gender = case.get('gender', 'N/A')
                            heartrate = case.get('heartrate', case.get('heart_rate', 'N/A'))
                            sbp = case.get('sbp', 'N/A')
                            dbp = case.get('dbp', 'N/A')
                            temperature = case.get('temperature', 'N/A')
                            o2sat = case.get('o2sat', 'N/A')
                            pain = case.get('pain', 'N/A')
                            
                            # ÊûÑÂª∫ËØ¶ÁªÜ‰ø°ÊÅØÂ≠óÁ¨¶‰∏≤
                            vitals = f"Age: {age}, Gender: {gender}, HR: {heartrate}, BP: {sbp}/{dbp}, Temp: {temperature}¬∞F, O2Sat: {o2sat}%, Pain: {pain}/10"
                            similarity_info = f"{similarities[i]:.3f}" if i < len(similarities) else 'N/A'
                            
                            # Debug: ÊâìÂç∞Ê°à‰æã‰ø°ÊÅØ
                            print(f"üîç Similar case {i+1}: {case.keys()}")
                            print(f"   Vitals: {vitals}")
                            
                            similar_cases.append({
                                'chief_complaint': case.get('chiefcomplaint', 'N/A'),
                                'triage_level': f"Level {case.get('acuity', 'Unknown')}",
                                'vitals': vitals,
                                'outcome': similarity_info
                            })
                    
                except Exception as e:
                    print(f"‚ùå Llama RAGÁ≥ªÁªüË∞ÉÁî®Â§±Ë¥•: {e}")
                    # ÂõûÈÄÄÂà∞Ê®°ÊãüÊ®°Âºè
                    llama_rag_system = MockRAGSystem()
                    prediction_result = llama_rag_system.predict_triage_level(patient_info)
                    triage_level = prediction_result['triage_level']
                    confidence = prediction_result['confidence']
                    reasoning = prediction_result['reasoning']
                    similar_cases = prediction_result['similar_cases']
                
            else:
                # Ê®°ÊãüRAGÁ≥ªÁªü
                print("‚ö†Ô∏è ‰ΩøÁî®Ê®°ÊãüLlama RAGÁ≥ªÁªü")
                if llama_rag_system is None:
                    llama_rag_system = MockRAGSystem()
                prediction_result = llama_rag_system.predict_triage_level(patient_info)
                triage_level = prediction_result['triage_level']
                confidence = prediction_result['confidence']
                reasoning = prediction_result['reasoning']
                similar_cases = prediction_result['similar_cases']
            
            model_used = 'llama_rag'
        
        # ËÆ°ÁÆóÂìçÂ∫îÊó∂Èó¥
        response_time = time.time() - start_time
        
        # ÊûÑÂª∫ÂìçÂ∫î
        response = {
            'success': True,
            'prediction': {
                'triage_level': triage_level,
                'confidence': confidence,
                'reasoning': reasoning,
                'response_time': round(response_time, 2),
                'similar_cases': similar_cases,
                'model': model_used
            },
            'patient_info': patient_info,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # Ê∑ªÂä†SHAPËß£ÈáäÊï∞ÊçÆÂà∞ÂìçÂ∫î
        if selected_model == 'tfidf_rf' and shap_explanation and shap_explanation.get('success'):
            response['shap_explanation'] = {
                'feature_contributions': shap_explanation['feature_contributions'][:10],
                'total_positive_contribution': shap_explanation['total_positive_contribution'],
                'total_negative_contribution': shap_explanation['total_negative_contribution'],
                'net_contribution': shap_explanation['net_contribution']
        }
        
        return jsonify(response)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }), 500

@app.route('/api/shap_explanation', methods=['POST'])
def get_shap_explanation():
    """Ëé∑ÂèñSHAPËß£ÈáäAPI"""
    
    try:
        # Á°Æ‰øùSHAPÊúçÂä°Â∑≤ÂàùÂßãÂåñ
        if not get_shap_explanation_for_prediction:
            return jsonify({
                'success': False,
                'error': 'SHAPËß£ÈáäÊúçÂä°‰∏çÂèØÁî®'
            }), 400
        
        # Ëé∑ÂèñÊÇ£ËÄÖ‰ø°ÊÅØ
        data = request.get_json()
        
        # È™åËØÅÂøÖÈúÄÂ≠óÊÆµ
        required_fields = ['chief_complaint', 'age', 'heart_rate', 'sbp', 'dbp', 'temperature', 'o2sat', 'pain']
        for field in required_fields:
            if field not in data:
                return jsonify({'error': f'Missing required field: {field}'}), 400
        
        # ÊûÑÂª∫ÊÇ£ËÄÖ‰ø°ÊÅØ
        patient_info = {
            'chief_complaint': data['chief_complaint'],
            'age_at_visit': data['age'],
            'heartrate': data['heart_rate'],
            'sbp': data['sbp'],
            'dbp': data['dbp'],
            'temperature': data['temperature'],
            'o2sat': data['o2sat'],
            'pain': data['pain'],
            'gender': data.get('gender', 'Unknown'),
            'arrival_transport': data.get('arrival_transport', 'WALK IN'),
            'arrival_time': data.get('arrival_time', '2024-01-15 12:00:00')
        }
        
        # Ëé∑ÂèñSHAPËß£Èáä
        shap_explanation = get_shap_explanation_for_prediction(patient_info)
        
        return jsonify({
            'success': True,
            'shap_explanation': shap_explanation,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """ÂÅ•Â∫∑Ê£ÄÊü•API"""
    return jsonify({
        'status': 'healthy',
        'llama_rag_system_loaded': llama_rag_system is not None,
        'xgboost_model_loaded': xgboost_model is not None,
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
    })

@app.route('/api/examples', methods=['GET'])
def get_examples():
    """Ëé∑ÂèñÁ§∫‰æãÁóÖ‰æã"""
    examples = [
        {
            'chief_complaint': 'Chest pain and shortness of breath',
            'age': 65,
            'heart_rate': 110,
            'sbp': 140,
            'dbp': 90,
            'temperature': 98.6,
            'o2sat': 92,
            'pain': 8,
            'gender': 'Male',
            'arrival_transport': 'WALK IN',
            'arrival_time': '13:32'
        },
        {
            'chief_complaint': 'Fever and cough for 3 days',
            'age': 45,
            'heart_rate': 95,
            'sbp': 130,
            'dbp': 85,
            'temperature': 101.2,
            'o2sat': 96,
            'pain': 4,
            'gender': 'Female',
            'arrival_transport': 'WALK IN',
            'arrival_time': '21:34'
        },
        {
            'chief_complaint': 'Headache and dizziness',
            'age': 30,
            'heart_rate': 75,
            'sbp': 120,
            'dbp': 80,
            'temperature': 98.4,
            'o2sat': 98,
            'pain': 6,
            'gender': 'Female',
            'arrival_transport': 'AMBULANCE',
            'arrival_time': '08:40'
        },
        {
            'chief_complaint': 'Minor finger laceration',
            'age': 25,
            'heart_rate': 70,
            'sbp': 115,
            'dbp': 75,
            'temperature': 98.2,
            'o2sat': 99,
            'pain': 2,
            'gender': 'Male',
            'arrival_transport': 'WALK IN',
            'arrival_time': '15:54'
        }
    ]
    
    return jsonify({'examples': examples})

if __name__ == '__main__':
    # ÂàùÂßãÂåñÊâÄÊúâÁ≥ªÁªü
    initialize_systems()
    
    # ÂêØÂä®FlaskÂ∫îÁî®
    print("üåê Starting medical triage frontend application...")
    print("üì± Access URL: http://localhost:5003")
    app.run(debug=True, host='0.0.0.0', port=5003) 