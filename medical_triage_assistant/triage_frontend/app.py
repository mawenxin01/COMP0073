#!/usr/bin/env python3
"""
Medical Triage Frontend Application - Flask Backend
Provides real-time triage prediction API using RAG + GPT models
"""

from flask import Flask, render_template, request, jsonify
from flask_cors import CORS
import pandas as pd
import numpy as np
import json
import time
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# å¯¼å…¥RAGç³»ç»Ÿ
try:
    from methods.llama_rag.llama_rag_triage import LlamaRAGTriageSystem
    LlamaRAGTriage = LlamaRAGTriageSystem
except ImportError as e:
    print(f"âš ï¸ Unable to import Llama RAG system: {e}")
    print("âš ï¸ Will use simulation mode")
    LlamaRAGTriage = None

# å¯¼å…¥ä¼ ç»ŸMLç³»ç»Ÿéœ€è¦çš„åº“
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD

# å¯¼å…¥å¿…è¦çš„åº“
import joblib
import numpy as np
import sys
import os

# æ·»åŠ methodsç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥CustomXGBClassifier
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'methods', 'tfidf_ml'))

# å¯¼å…¥CustomXGBClassifier
try:
    from methods.tfidf_ml.nosvd import CustomXGBClassifier
    print("âœ… CustomXGBClassifier imported successfully")
except ImportError as e:
    print(f"âš ï¸ Unable to import CustomXGBClassifier: {e}")
    CustomXGBClassifier = None

# å¯¼å…¥SHAPè§£é‡ŠæœåŠ¡
try:
    from methods.llama_rag.shap_explainer_service import get_shap_explanation_for_prediction, initialize_shap_service
    print("âœ… SHAP explanation service imported successfully")
except ImportError as e:
    print(f"âš ï¸ Unable to import SHAP explanation service: {e}")
    get_shap_explanation_for_prediction = None
    initialize_shap_service = None

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# è¾…åŠ©å‡½æ•°
def _format_time_display(arrival_time):
    """å°†å®Œæ•´æ—¶é—´æ ¼å¼è½¬æ¢ä¸ºåªæ˜¾ç¤ºæ—¶åˆ†çš„æ ¼å¼"""
    if not arrival_time:
        return None
    try:
        dt = pd.to_datetime(arrival_time)
        return dt.strftime('%H:%M')
    except:
        return arrival_time

# å…¨å±€å˜é‡
llama_rag_system = None
xgboost_model = None
tfidf_vectorizer = None  
svd_model = None  # SVDé™ç»´æ¨¡å‹
feature_scaler = None
case_database = None
watsonx_client = None  # Watsonxå®¢æˆ·ç«¯

class MockRAGSystem:
    """Mock RAG system for demonstration"""
    
    def __init__(self):
        self.embedding_model = None
        self.faiss_index = None
        
    def predict_triage_level(self, patient_info, k=5):
        """Mock triage prediction"""
        
        # ç®€å•çš„è§„åˆ™å¼•æ“
        chief_complaint = patient_info.get('chief_complaint', '').lower()
        heart_rate = patient_info.get('heart_rate', 80)
        sbp = patient_info.get('sbp', 120)
        dbp = patient_info.get('dbp', 80)
        temperature = patient_info.get('temperature', 98.6)
        o2sat = patient_info.get('o2sat', 98)
        pain = patient_info.get('pain', 5)
        age = patient_info.get('age', 50)
        
        # å±é‡ç—‡çŠ¶å…³é”®è¯
        critical_keywords = ['chest pain', 'shortness of breath', 'unconscious', 'cardiac arrest', 
                           'stroke', 'seizure', 'trauma', 'bleeding', 'shock']
        
        # ä¸¥é‡ç—‡çŠ¶å…³é”®è¯
        severe_keywords = ['fever', 'vomiting', 'diarrhea', 'headache', 'abdominal pain', 
                          'dizziness', 'weakness', 'nausea']
        
        # ç”Ÿå‘½ä½“å¾è¯„ä¼°
        vital_score = 0
        if heart_rate > 100 or heart_rate < 60:
            vital_score += 1
        if sbp < 90 or sbp > 180:
            vital_score += 1
        if temperature > 100.4:
            vital_score += 1
        if o2sat < 95:
            vital_score += 1
        if pain > 7:
            vital_score += 1
        
        # å¹´é¾„é£é™©
        age_risk = 0
        if age > 65:
            age_risk = 1
        
        # åˆ†è¯Šç­‰çº§åˆ¤æ–­
        if any(keyword in chief_complaint for keyword in critical_keywords) or vital_score >= 3:
            triage_level = 1  # å±é‡
            confidence = 0.85
            reasoning = "æ‚£è€…è¡¨ç°å‡ºå±é‡ç—‡çŠ¶æˆ–ç”Ÿå‘½ä½“å¾å¼‚å¸¸ï¼Œéœ€è¦ç«‹å³åŒ»ç–—å¹²é¢„"
        elif any(keyword in chief_complaint for keyword in severe_keywords) or vital_score >= 2 or age_risk:
            triage_level = 2  # ä¸¥é‡
            confidence = 0.75
            reasoning = "æ‚£è€…ç—‡çŠ¶ä¸¥é‡æˆ–å­˜åœ¨é£é™©å› ç´ ï¼Œéœ€è¦åŠæ—¶åŒ»ç–—è¯„ä¼°"
        elif vital_score >= 1 or pain > 5:
            triage_level = 3  # ä¸­ç­‰
            confidence = 0.70
            reasoning = "æ‚£è€…ç—‡çŠ¶ä¸­ç­‰ï¼Œéœ€è¦åŒ»ç–—è¯„ä¼°ä½†éç´§æ€¥"
        else:
            triage_level = 4  # è½»å¾®
            confidence = 0.80
            reasoning = "æ‚£è€…ç—‡çŠ¶è½»å¾®ï¼Œå¯ä»¥ç­‰å¾…å¸¸è§„åŒ»ç–—è¯„ä¼°"
        
        # è¿”å›ä¸çœŸå®LlamaRAGTriageSystemç›¸åŒçš„æ ¼å¼ï¼š(triage_level, reasoning, similar_cases, similarities)
        similar_cases = [
            {'chief_complaint': 'chest pain', 'triage_level': 1, 'outcome': 'MI confirmed'},
            {'chief_complaint': 'fever and cough', 'triage_level': 2, 'outcome': 'Pneumonia'},
            {'chief_complaint': 'headache', 'triage_level': 3, 'outcome': 'Tension headache'}
        ]
        similarities = [0.85, 0.75, 0.65]  # æ¨¡æ‹Ÿç›¸ä¼¼åº¦åˆ†æ•°
        
        return triage_level, reasoning, similar_cases, similarities

def initialize_systems():
    """åˆå§‹åŒ–æ‰€æœ‰é¢„æµ‹ç³»ç»Ÿ"""
    global llama_rag_system, xgboost_model, feature_scaler, case_database
    
    # 1. åˆå§‹åŒ–Llama RAGç³»ç»Ÿ - ç›´æ¥åŠ è½½é¢„æ„å»ºçš„ç´¢å¼•
    try:
        if LlamaRAGTriage:
            print("ğŸš€ Initializing Llama RAG system...")
            llama_rag_system = LlamaRAGTriage()
            
            # ç›´æ¥åŠ è½½é¢„æ„å»ºçš„ç´¢å¼•ï¼Œä¸æ¶‰åŠåŸå§‹æ•°æ®
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.join(current_dir, "..")
            
            # å°è¯•åŠ è½½å·²è®­ç»ƒå¥½çš„ç´¢å¼•ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
            possible_index_paths = [
                os.path.join(project_root, "methods/llama_rag/llama_rag_train_only_index_stable"),  # ç¨³å®šç‰ˆæœ¬ç´¢å¼•
                # å¦‚æœç´¢å¼•ä¸å­˜åœ¨ï¼Œåˆ™æç¤ºç”¨æˆ·å…ˆè¿è¡Œè®­ç»ƒ
            ]
            
            loaded = False
            for index_path in possible_index_paths:
                print(f"ğŸ” Attempting to load index: {index_path}")
                # Check if FAISS index files exist (need both .index and .pkl files)
                faiss_index_path = f"{index_path}_faiss.index"
                metadata_path = f"{index_path}_metadata.pkl"
                
                if os.path.exists(faiss_index_path) and os.path.exists(metadata_path):
                    print(f"âœ… Found pre-built index: {index_path}")
                    try:
                        # åˆå§‹åŒ–çœŸå®çš„Llama RAGç³»ç»Ÿ
                        from methods.llama_rag.llama_rag_triage import LlamaRAGTriageSystem
                        llama_rag_system = LlamaRAGTriageSystem()
                        # åŠ è½½é¢„æ„å»ºç´¢å¼•
                        llama_rag_system.case_retriever.vector_store.load_index(index_path)
                        
                        # æ ‡è®°ç³»ç»Ÿä¸ºå·²åˆå§‹åŒ–
                        llama_rag_system.case_retriever.initialized = True
                        llama_rag_system.is_initialized = True
                        
                        print(f"âœ… Successfully loaded pre-built index: {index_path}")
                        loaded = True
                        
                        # æ£€æŸ¥ç´¢å¼•æ•°æ®é‡ï¼Œè­¦å‘Šæ½œåœ¨çš„æ•°æ®æ³„æ¼
                        if hasattr(llama_rag_system.case_retriever, 'vector_store') and hasattr(llama_rag_system.case_retriever.vector_store, 'case_database'):
                            indexed_count = len(llama_rag_system.case_retriever.vector_store.case_database)
                            expected_train_size = int(189780 * 0.8)  # çº¦151,824
                            print(f"ğŸ“Š Loaded index contains {indexed_count} cases")
                            
                            if indexed_count > (expected_train_size + 5000):
                                print(f"âš ï¸ Data leakage warning: Index data size ({indexed_count}) exceeds expected training size ({expected_train_size})")
                                print(f"   May contain test data, evaluation results may be inflated")
                            elif indexed_count < (expected_train_size - 5000):
                                print(f"âš ï¸ Data size too small: Index data size ({indexed_count}) less than expected training size")
                            else:
                                print(f"âœ… Index data size reasonable: {indexed_count} cases (expected ~{expected_train_size})")
                        break
                        
                    except Exception as e:
                        print(f"âŒ Failed to load index: {e}")
                        continue
                else:
                    print(f"âš ï¸ Index does not exist or failed to load: {index_path}")
            
            if not loaded:
                print("âŒ No available pre-built index found")
                print("ğŸ’¡ Please run the following commands to build index:")
                print("   cd medical_triage_assistant/methods/llama_rag")
                print("   python llama_rag_triage.py")
                print("âš ï¸ Temporarily using simulation mode")
                llama_rag_system = MockRAGSystem()
            else:
                print("âœ… Llama RAG system initialization complete (using pre-built index)")
                
        else:
            print("âš ï¸ ä½¿ç”¨æ¨¡æ‹ŸLlama RAGç³»ç»Ÿ")
            llama_rag_system = MockRAGSystem()
            
    except Exception as e:
        print(f"âŒ Llama RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        print("âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        llama_rag_system = MockRAGSystem()
    
    # 2. åˆå§‹åŒ–TFIDF + Random Forestæ¨¡å‹
    global xgboost_model, tfidf_vectorizer, svd_model, watsonx_client
    try:
        print("ğŸ¯ åˆå§‹åŒ–TFIDF + Random Forestæ¨¡å‹...")
        
        # ç¡®ä¿project_rootå·²å®šä¹‰
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.join(current_dir, "..")
        
        # åŠ è½½TFIDF + Random Forestæ¨¡å‹
        xgboost_path = os.path.join(project_root, "models", "TFIDF-rf.pkl")
        vectorizer_path = os.path.join(project_root, "models", "TFIDF-rf-vectorizer.pkl")
        svd_path = os.path.join(project_root, "models", "TFIDF-rf-svd.pkl")
        
        if os.path.exists(xgboost_path):
            xgboost_model = joblib.load(xgboost_path)
            print("âœ… TFIDF + Random Forestæ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # åŠ è½½TF-IDFå‘é‡åŒ–å™¨
            if os.path.exists(vectorizer_path):
                tfidf_vectorizer = joblib.load(vectorizer_path)
                print("âœ… TF-IDFå‘é‡åŒ–å™¨åŠ è½½æˆåŠŸ")
            else:
                print(f"âŒ TF-IDFå‘é‡åŒ–å™¨æ–‡ä»¶ä¸å­˜åœ¨: {vectorizer_path}")
                tfidf_vectorizer = None
            
            # åŠ è½½SVDæ¨¡å‹
            if os.path.exists(svd_path):
                svd_model = joblib.load(svd_path)
                print("âœ… SVDæ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                print(f"âŒ SVDæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {svd_path}")
                svd_model = None
                
        else:
            print(f"âŒ TFIDF + Random Forestæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {xgboost_path}")
            xgboost_model = None
            tfidf_vectorizer = None
            svd_model = None
        
        # åˆå§‹åŒ–Watsonxå®¢æˆ·ç«¯
        try:
            from medical_triage_assistant.config.azure_simple import IBM_API_KEY, IBM_ENDPOINT, IBM_PROJECT_ID, IBM_MODEL_NAME
            from ibm_watsonx_ai.foundation_models import ModelInference
            from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as Meta
            from ibm_watsonx_ai import Credentials
            
            credentials = Credentials(api_key=IBM_API_KEY, url=IBM_ENDPOINT)
            watsonx_client = ModelInference(
                model_id=IBM_MODEL_NAME,
                credentials=credentials,
                project_id=IBM_PROJECT_ID,
                params={Meta.MAX_NEW_TOKENS: 100, Meta.TEMPERATURE: 0.1}
            )
            print("âœ… Watsonxå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ Watsonxå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            watsonx_client = None
            
    except Exception as e:
        print(f"âŒ TFIDF + Random Forestæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
        xgboost_model = None
        watsonx_client = None
    
    # 3. åˆå§‹åŒ–SHAPè§£é‡ŠæœåŠ¡
    try:
        print("ğŸ” åˆå§‹åŒ–SHAPè§£é‡ŠæœåŠ¡...")
        if initialize_shap_service:
            if initialize_shap_service():
                print("âœ… SHAPè§£é‡ŠæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            else:
                print("âš ï¸ SHAPè§£é‡ŠæœåŠ¡åˆå§‹åŒ–å¤±è´¥")
        else:
            print("âš ï¸ SHAPè§£é‡ŠæœåŠ¡ä¸å¯ç”¨")
    except Exception as e:
        print(f"âŒ SHAPè§£é‡ŠæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        


@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')

@app.route('/api/predict', methods=['POST'])
def predict_triage():
    """åˆ†è¯Šé¢„æµ‹API"""
    
    try:
        # ç¡®ä¿ç³»ç»Ÿå·²åˆå§‹åŒ–
        global llama_rag_system, xgboost_model, watsonx_client
        if llama_rag_system is None or xgboost_model is None:
            initialize_systems()
            
        # è·å–æ‚£è€…ä¿¡æ¯
        data = request.get_json()
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ['chief_complaint', 'age', 'heart_rate', 'sbp', 'dbp', 'temperature', 'o2sat', 'pain']
        for field in required_fields:
            if field not in data:
                return jsonify({'error': f'Missing required field: {field}'}), 400
        
        # è®°å½•è¯·æ±‚æ—¶é—´
        start_time = time.time()
        
        # è·å–é€‰æ‹©çš„æ¨¡å‹
        selected_model = data.get('model', 'gpt_rag')
        
        # æ„å»ºæ‚£è€…ä¿¡æ¯
        patient_info = {
            'chiefcomplaint': data['chief_complaint'],
            'chief_complaint': data['chief_complaint'],  # ä¸ºä¼ ç»ŸMLä¿ç•™
            'age_at_visit': data['age'],
            'age': data['age'],  # ä¸ºä¼ ç»ŸMLä¿ç•™
            'heartrate': data['heart_rate'],
            'heart_rate': data['heart_rate'],  # ä¸ºä¼ ç»ŸMLä¿ç•™
            'sbp': data['sbp'],
            'dbp': data['dbp'],
            'temperature': data['temperature'],
            'o2sat': data['o2sat'],
            'pain': data['pain'],
            'gender': data.get('gender', 'Unknown'),
            'arrival_transport': data.get('arrival_transport', 'WALK IN'),
            'arrival_time': pd.to_datetime(data.get('arrival_time', None)).strftime('%H:%M') if data.get('arrival_time', None) else None  # åªæ˜¾ç¤ºæ—¶åˆ†
        }
        
        # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
        print(f"ğŸ” Selected model: {selected_model}")
        
        if selected_model == 'tfidf_rf':
            # ä½¿ç”¨TFIDF + Random Forestæ¨¡å‹è¿›è¡Œé¢„æµ‹
            print("ğŸ“Š Using TFIDF + Random Forest model for prediction")
            
            try:
                if xgboost_model is not None:
                    if tfidf_vectorizer is not None and svd_model is not None:
                        print("âœ… Using TFIDF + Random Forest model (complete 33 features)")
                    
                    # 1. æå–å…³é”®è¯
                    chief_complaint = patient_info.get('chief_complaint', '')
                    keywords = chief_complaint  # é»˜è®¤ä½¿ç”¨åŸå§‹æ–‡æœ¬
                    
                    if watsonx_client is not None:
                        try:
                            prompt = f"""
                            ä½œä¸ºåŒ»ç–—ä¸“å®¶ï¼Œè¯·ä»ä»¥ä¸‹ä¸»è¯‰ä¸­æå–æœ€é‡è¦çš„åŒ»å­¦å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼š

                            ä¸»è¯‰: {chief_complaint}

                            å…³é”®è¯:"""
                            
                            response = watsonx_client.generate_text(prompt=prompt)
                            keywords = response.strip()
                            print(f"ğŸ” Keywords extracted by Watsonx: {keywords}")
                        except Exception as e:
                            print(f"âš ï¸ Watsonx keyword extraction failed: {e}")
                    
                    # 2. å¤„ç†æ–‡æœ¬ç‰¹å¾ï¼ˆä½¿ç”¨çœŸæ­£çš„TF-IDF + SVDï¼‰
                    print(f"ğŸ” Processing keywords: {keywords}")
                    
                    # TF-IDFå˜æ¢
                    keywords_tfidf = tfidf_vectorizer.transform([keywords])
                    print(f"âœ… TF-IDF feature shape: {keywords_tfidf.shape}")
                    
                    # SVDé™ç»´
                    keywords_svd = svd_model.transform(keywords_tfidf)
                    print(f"âœ… SVD feature shape: {keywords_svd.shape}")
                    
                    # 3. å¤„ç†æ—¶é—´ç‰¹å¾
                    arrival_time = patient_info.get('arrival_time', '2024-01-15 12:00:00')
                    try:
                        dt = pd.to_datetime(arrival_time)
                        hour = dt.hour
                        if 0 <= hour < 6:
                            time_period = 0  # å‡Œæ™¨
                        elif 6 <= hour < 12:
                            time_period = 1  # ä¸Šåˆ
                        elif 12 <= hour < 18:
                            time_period = 2  # ä¸‹åˆ
                        else:
                            time_period = 3  # æ™šä¸Š
                    except:
                        time_period = 2  # é»˜è®¤ä¸‹åˆ
                    
                    # 4. æ„å»ºæ•°å€¼ç‰¹å¾ï¼ˆ8ä¸ªåŸºç¡€æ•°å€¼ç‰¹å¾ï¼‰
                    numerical_features = [
                        float(patient_info.get('age', 50)),
                        float(patient_info.get('pain', 0)),
                        float(patient_info.get('temperature', 98.6)),
                        float(patient_info.get('heart_rate', 80)),
                        float(patient_info.get('sbp', 120)),
                        float(patient_info.get('dbp', 80)),
                        float(patient_info.get('o2sat', 98)),
                        float(time_period)
                    ]
                    
                    # 5. å¤„ç†åˆ†ç±»ç‰¹å¾ï¼ˆ5ä¸ªone-hotç¼–ç ç‰¹å¾ï¼‰
                    gender = patient_info.get('gender', 'Unknown').upper()
                    gender_m = 1 if gender == 'M' else 0
                    
                    transport = patient_info.get('arrival_transport', 'WALK IN').upper()
                    transport_helicopter = 1 if transport == 'HELICOPTER' else 0
                    transport_other = 1 if transport == 'OTHER' else 0
                    transport_unknown = 1 if transport == 'UNKNOWN' else 0
                    transport_walk_in = 1 if transport == 'WALK IN' else 0
                    
                    categorical_features = [
                        gender_m,
                        transport_helicopter,
                        transport_other,
                        transport_unknown,
                        transport_walk_in
                    ]
                    
                    # 6. åˆå¹¶æ‰€æœ‰ç‰¹å¾ï¼ˆ33ä¸ªç‰¹å¾ï¼š8æ•°å€¼ + 5åˆ†ç±» + 20 SVDï¼‰
                    all_features = np.concatenate([
                        numerical_features,        # 8ä¸ªæ•°å€¼ç‰¹å¾
                        categorical_features,      # 5ä¸ªåˆ†ç±»ç‰¹å¾  
                        keywords_svd.flatten()     # 20ä¸ªSVDç‰¹å¾
                    ])
                    
                    print(f"âœ… Final feature vector shape: {all_features.shape} (should be 33)")
                    print(f"   Numerical features: {len(numerical_features)}")
                    print(f"   Categorical features: {len(categorical_features)}")
                    print(f"   SVD features: {keywords_svd.shape[1]}")
                    
                    # 7. ä½¿ç”¨TFIDF + Random Forestæ¨¡å‹é¢„æµ‹
                    prediction = xgboost_model.predict([all_features])[0]
                    prediction_proba = xgboost_model.predict_proba([all_features])[0]
                    
                    # è½¬æ¢å›åŸå§‹åˆ†è¯Šç­‰çº§ (0-4 -> 1-5)
                    triage_level = int(prediction) + 1
                    confidence = float(np.max(prediction_proba))
                    
                    # åˆ†è¯Šç­‰çº§å«ä¹‰
                    level_meanings = {
                        1: "Critical (ç«‹å³)",
                        2: "Severe (æ€¥è¯Š)",
                        3: "Moderate (ç´§æ€¥)",
                        4: "Mild (è¾ƒæ€¥)",
                        5: "Minor (éæ€¥)"
                    }
                    
                    # è·å–SHAPè§£é‡Š
                    shap_explanation = None
                    if get_shap_explanation_for_prediction:
                        try:
                            shap_explanation = get_shap_explanation_for_prediction(patient_info)
                            print("âœ… SHAPè§£é‡Šç”ŸæˆæˆåŠŸ")
                        except Exception as e:
                            print(f"âš ï¸ SHAPè§£é‡Šç”Ÿæˆå¤±è´¥: {e}")
                    
                    # TFIDFæ¨¡å‹ä¸æä¾›reasoningï¼Œåªè¿”å›åˆ†è¯Šçº§åˆ«
                    reasoning = ""
                    
                    # ä¸æä¾›ç›¸ä¼¼æ¡ˆä¾‹
                    similar_cases = []
                        
                else:
                    print("âš ï¸ TFIDF + Random Forestæ¨¡å‹ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
                    triage_level = 3
                    confidence = 0.5
                    reasoning = ""
                    similar_cases = []
                
            except Exception as e:
                print(f"âŒ TFIDF + Random Foresté¢„æµ‹å¤±è´¥: {e}")
                triage_level = 3
                confidence = 0.0
                reasoning = ""
                similar_cases = []
                
            model_used = 'tfidf_rf'
            
        else:
            # ä½¿ç”¨Llama RAGç³»ç»Ÿï¼ˆé»˜è®¤ï¼‰
            print(f"ğŸ¤– ä½¿ç”¨Llama RAGç³»ç»Ÿè¿›è¡Œé¢„æµ‹")
            if llama_rag_system is not None and hasattr(llama_rag_system, 'predict_triage_level'):
                # çœŸå®Llama RAGç³»ç»Ÿ
                print("âœ… ä½¿ç”¨çœŸå®Llama RAGç³»ç»Ÿï¼ˆVector-Onlyæ£€ç´¢ - æœ€å¿«æ¨¡å¼ï¼‰")
                try:
                    # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                    case_dict = {
                        'chief_complaint': patient_info.get('chief_complaint', ''),
                        'age_at_visit': patient_info.get('age', 50),
                        'gender': patient_info.get('gender', 'Unknown'),
                        'heartrate': patient_info.get('heart_rate', 80),
                        'sbp': patient_info.get('sbp', 120),
                        'dbp': patient_info.get('dbp', 80),
                        'temperature': patient_info.get('temperature', 98.6),
                        'o2sat': patient_info.get('o2sat', 98),
                        'pain': patient_info.get('pain', 5),
                        'arrival_transport': patient_info.get('arrival_method', 'Unknown'),
                        'time_period': patient_info.get('time_period', 2)
                    }
                    
                    # è°ƒç”¨LLaMA RAGç³»ç»Ÿï¼ˆä½¿ç”¨Vector-Onlyæ£€ç´¢ - æœ€å¿«æ¨¡å¼ï¼‰
                    # æ€§èƒ½é…ç½®ï¼šVector-Onlyæ¨¡å¼ï¼Œæœ€å¿«çš„æ£€ç´¢é€Ÿåº¦
                    k_retrieve = 5  # Vector-Onlyæ£€ç´¢ (~30-50msï¼Œæœ€å¿«)
                    
                    start_retrieval = time.time()
                    triage_level, reasoning, similar_cases_raw, similarities = llama_rag_system.predict_triage_level(case_dict, k=k_retrieve)
                    retrieval_time = time.time() - start_retrieval
                    print(f"â±ï¸ RAGæ£€ç´¢+ç”Ÿæˆæ—¶é—´: {retrieval_time:.3f}s")
                    
                    confidence = 0.8  # é»˜è®¤ç½®ä¿¡åº¦
                    if similarities:
                        confidence = min(0.95, max(0.6, np.mean(similarities)))
                    
                    # è½¬æ¢ç›¸ä¼¼æ¡ˆä¾‹æ ¼å¼
                    similar_cases = []
                    if similar_cases_raw:
                        for i, case in enumerate(similar_cases_raw[:3]):  # å–å‰3ä¸ª
                            # æ„å»ºå®Œæ•´çš„æ¡ˆä¾‹ä¿¡æ¯
                            age = case.get('age_at_visit', case.get('age', 'N/A'))
                            gender = case.get('gender', 'N/A')
                            heartrate = case.get('heartrate', case.get('heart_rate', 'N/A'))
                            sbp = case.get('sbp', 'N/A')
                            dbp = case.get('dbp', 'N/A')
                            temperature = case.get('temperature', 'N/A')
                            o2sat = case.get('o2sat', 'N/A')
                            pain = case.get('pain', 'N/A')
                            
                            # æ„å»ºè¯¦ç»†ä¿¡æ¯å­—ç¬¦ä¸²
                            vitals = f"Age: {age}, Gender: {gender}, HR: {heartrate}, BP: {sbp}/{dbp}, Temp: {temperature}Â°F, O2Sat: {o2sat}%, Pain: {pain}/10"
                            similarity_info = f"{similarities[i]:.3f}" if i < len(similarities) else 'N/A'
                            
                            # Debug: æ‰“å°æ¡ˆä¾‹ä¿¡æ¯
                            print(f"ğŸ” Similar case {i+1}: {case.keys()}")
                            print(f"   Vitals: {vitals}")
                            
                            similar_cases.append({
                                'chief_complaint': case.get('chiefcomplaint', 'N/A'),
                                'triage_level': f"Level {case.get('acuity', 'Unknown')}",
                                'vitals': vitals,
                                'outcome': similarity_info
                            })
                    
                except Exception as e:
                    print(f"âŒ Llama RAGç³»ç»Ÿè°ƒç”¨å¤±è´¥: {e}")
                    # å›é€€åˆ°æ¨¡æ‹Ÿæ¨¡å¼
                    llama_rag_system = MockRAGSystem()
                    prediction_result = llama_rag_system.predict_triage_level(patient_info)
                    triage_level = prediction_result['triage_level']
                    confidence = prediction_result['confidence']
                    reasoning = prediction_result['reasoning']
                    similar_cases = prediction_result['similar_cases']
                
            else:
                # æ¨¡æ‹ŸRAGç³»ç»Ÿ
                print("âš ï¸ ä½¿ç”¨æ¨¡æ‹ŸLlama RAGç³»ç»Ÿ")
                if llama_rag_system is None:
                    llama_rag_system = MockRAGSystem()
                prediction_result = llama_rag_system.predict_triage_level(patient_info)
                triage_level = prediction_result['triage_level']
                confidence = prediction_result['confidence']
                reasoning = prediction_result['reasoning']
                similar_cases = prediction_result['similar_cases']
            
            model_used = 'llama_rag'
        
        # è®¡ç®—å“åº”æ—¶é—´
        response_time = time.time() - start_time
        
        # æ„å»ºå“åº”
        response = {
            'success': True,
            'prediction': {
                'triage_level': triage_level,
                'confidence': confidence,
                'reasoning': reasoning,
                'response_time': round(response_time, 2),
                'similar_cases': similar_cases,
                'model': model_used
            },
            'patient_info': patient_info,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # æ·»åŠ SHAPè§£é‡Šæ•°æ®åˆ°å“åº”
        if selected_model == 'tfidf_rf' and shap_explanation and shap_explanation.get('success'):
            response['shap_explanation'] = {
                'feature_contributions': shap_explanation['feature_contributions'][:10],
                'total_positive_contribution': shap_explanation['total_positive_contribution'],
                'total_negative_contribution': shap_explanation['total_negative_contribution'],
                'net_contribution': shap_explanation['net_contribution']
        }
        
        return jsonify(response)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }), 500

@app.route('/api/shap_explanation', methods=['POST'])
def get_shap_explanation():
    """è·å–SHAPè§£é‡ŠAPI"""
    
    try:
        # ç¡®ä¿SHAPæœåŠ¡å·²åˆå§‹åŒ–
        if not get_shap_explanation_for_prediction:
            return jsonify({
                'success': False,
                'error': 'SHAPè§£é‡ŠæœåŠ¡ä¸å¯ç”¨'
            }), 400
        
        # è·å–æ‚£è€…ä¿¡æ¯
        data = request.get_json()
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ['chief_complaint', 'age', 'heart_rate', 'sbp', 'dbp', 'temperature', 'o2sat', 'pain']
        for field in required_fields:
            if field not in data:
                return jsonify({'error': f'Missing required field: {field}'}), 400
        
        # æ„å»ºæ‚£è€…ä¿¡æ¯
        patient_info = {
            'chief_complaint': data['chief_complaint'],
            'age_at_visit': data['age'],
            'heartrate': data['heart_rate'],
            'sbp': data['sbp'],
            'dbp': data['dbp'],
            'temperature': data['temperature'],
            'o2sat': data['o2sat'],
            'pain': data['pain'],
            'gender': data.get('gender', 'Unknown'),
            'arrival_transport': data.get('arrival_transport', 'WALK IN'),
            'arrival_time': data.get('arrival_time', '2024-01-15 12:00:00')
        }
        
        # è·å–SHAPè§£é‡Š
        shap_explanation = get_shap_explanation_for_prediction(patient_info)
        
        return jsonify({
            'success': True,
            'shap_explanation': shap_explanation,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥API"""
    return jsonify({
        'status': 'healthy',
        'llama_rag_system_loaded': llama_rag_system is not None,
        'xgboost_model_loaded': xgboost_model is not None,
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
    })

@app.route('/api/examples', methods=['GET'])
def get_examples():
    """è·å–ç¤ºä¾‹ç—…ä¾‹"""
    examples = [
        {
            'chief_complaint': 'Chest pain and shortness of breath',
            'age': 65,
            'heart_rate': 110,
            'sbp': 140,
            'dbp': 90,
            'temperature': 98.6,
            'o2sat': 92,
            'pain': 8,
            'gender': 'Male',
            'arrival_transport': 'WALK IN',
            'arrival_time': '13:32'
        },
        {
            'chief_complaint': 'Fever and cough for 3 days',
            'age': 45,
            'heart_rate': 95,
            'sbp': 130,
            'dbp': 85,
            'temperature': 101.2,
            'o2sat': 96,
            'pain': 4,
            'gender': 'Female',
            'arrival_transport': 'WALK IN',
            'arrival_time': '21:34'
        },
        {
            'chief_complaint': 'Headache and dizziness',
            'age': 30,
            'heart_rate': 75,
            'sbp': 120,
            'dbp': 80,
            'temperature': 98.4,
            'o2sat': 98,
            'pain': 6,
            'gender': 'Female',
            'arrival_transport': 'AMBULANCE',
            'arrival_time': '08:40'
        },
        {
            'chief_complaint': 'Minor finger laceration',
            'age': 25,
            'heart_rate': 70,
            'sbp': 115,
            'dbp': 75,
            'temperature': 98.2,
            'o2sat': 99,
            'pain': 2,
            'gender': 'Male',
            'arrival_transport': 'WALK IN',
            'arrival_time': '15:54'
        }
    ]
    
    return jsonify({'examples': examples})

if __name__ == '__main__':
    # åˆå§‹åŒ–æ‰€æœ‰ç³»ç»Ÿ
    initialize_systems()
    
    # å¯åŠ¨Flaskåº”ç”¨
    print("ğŸŒ Starting medical triage frontend application...")
    print("ğŸ“± Access URL: http://localhost:5003")
    app.run(debug=True, host='0.0.0.0', port=5003) 